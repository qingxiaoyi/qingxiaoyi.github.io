<!DOCTYPE HTML>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>python编写简易爬虫 | Xiaoyi&#39;s blog</title>
  <meta name="author" content="Xiaoyi Qing">

  
  <meta name="description" content="什么是爬虫？网络爬虫（web crawler），其实就是一种脚本，能够按照一定的规则自动的抓取万维网上的信息。
爬虫的思路先输入一个网址，浏览器拿到网址后通过域名解析出IP后（http服务）发送给服务器一个请求；服务器会根据请求做相应处理后在返回给浏览器（响应）；浏览器收到响应后会对收到的内容解析、">
  

  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="python编写简易爬虫">
  <meta property="og:site_name" content="Xiaoyi&#39;s blog">

  
  

  
    <meta property="og:image" content>
  

  
  <link href="/css/images/favicon.ico" rel="icon">
  

  <link rel="alternate" href="/atom.xml" title="Xiaoyi&#39;s blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  


  <!-- baidu webmaster push -->
  <script src="//push.zhanzhang.baidu.com/push.js"></script>

</head>
</html>

<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">Xiaoyi&#39;s blog</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div></header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2019-09-23T08:05:36.000Z"><a href="/2019/09/23/python编写简易爬虫/">2019-09-23</a></time>
      
      
  
    <h1 class="title">python编写简易爬虫</h1>
  

    </header>
    <div class="entry">
      
        <h2 id="什么是爬虫？"><a href="#什么是爬虫？" class="headerlink" title="什么是爬虫？"></a>什么是爬虫？</h2><p>网络爬虫（web crawler），其实就是一种脚本，能够按照一定的规则自动的抓取万维网上的信息。</p>
<h2 id="爬虫的思路"><a href="#爬虫的思路" class="headerlink" title="爬虫的思路"></a>爬虫的思路</h2><p>先输入一个网址，浏览器拿到网址后通过域名解析出IP后（http服务）发送给服务器一个请求；服务器会根据请求做相应处理后在返回给浏览器（响应）；浏览器收到响应后会对收到的内容解析、渲染，在展示给用户。而爬虫就是用程序模拟浏览器发送http请求，通过url进行一系列的信息数据等资源的抓取。</p>
<h2 id="爬虫流程"><a href="#爬虫流程" class="headerlink" title="爬虫流程"></a>爬虫流程</h2><blockquote>
<p>目标数据  </p>
</blockquote>
<p>-网站<br>-页面  </p>
<blockquote>
<p>分析数据加载流程</p>
</blockquote>
<p>-分析目标数据所对应的url  </p>
<blockquote>
<p>下载数据  </p>
</blockquote>
<blockquote>
<p>清洗处理数据  </p>
</blockquote>
<blockquote>
<p>数据持久化  </p>
</blockquote>
<p> 清楚原理后开始爬虫！这次爬虫的目标是<a href="http://www.xbiqugew.com/" target="_blank" rel="noopener">笔趣阁</a>上的辰东的《圣墟》  </p>
<h2 id="开始爬虫"><a href="#开始爬虫" class="headerlink" title="开始爬虫"></a>开始爬虫</h2><blockquote>
<p>首先导入爬虫所需要的库  </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import re</span><br></pre></td></tr></table></figure>

<p>requests:爬虫需要请求http模块，可以方便进行数据爬取<br>re:re是正则表达式的库，可以更精确指定抓取数据的位置</p>
<blockquote>
<p>下载一个页面  </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">url = &apos;http://www.xbiqugew.com/book/18725/&apos;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>模拟浏览器发送http请求  </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">response = requests.get(url)</span><br><span class="line">response.encoding =&apos;gbk&apos;</span><br></pre></td></tr></table></figure>

<p>此处html的字符集我试了很多个种字符集都是乱码，最后找到一个诀窍，直接到html代码里找到头部(head)，一般前面几行就会写出这个html的字符集。这个html的字符集为gbk  </p>
<p><img src="https://i.loli.net/2020/01/15/EW13N2wRf6n7SPc.jpg" alt="html中查看字符集"> </p>
<blockquote>
<p>网页源码</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">html = response.text</span><br></pre></td></tr></table></figure>

<blockquote>
<p>获取小说标题</p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">title = re.findall(r&apos;&lt;meta property=&quot;og:title&quot; content=&quot;(.*?)&quot;&gt;&apos;,html)</span><br></pre></td></tr></table></figure>

<p>这里的小说标题就是用爬虫抓取出来的数据了。  </p>
<p>  从html网页源码中找到需要抓取内容周围具有唯一性的代码段，将需要抓取的内容删除，使用(.*?)来代替，这里的括号里点星问就是需要抓取的内容。  </p>
<blockquote>
<p>获取每一章节的信息（章节，url）  </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dl = re.findall(r&apos;&lt;dt&gt;《圣墟》正文&lt;/dt&gt;.*?&lt;/dl&gt;&apos;,html,re.S)[0]</span><br><span class="line">chapter_info_list = re.findall(r&apos;&lt;dd&gt;&lt;a href=&quot;(.*?)&quot;&gt;(.*?)&lt;/a&gt;&lt;/dd&gt;&apos;,dl)</span><br></pre></td></tr></table></figure>

<p>和上面获取小说标题信息一样，知识抓取内容更多更杂乱一点，不过都是通过re.findall()和(.*?)来抓取内容。  </p>
<blockquote>
<p>循环每一个章节，分别去下载  </p>
</blockquote>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for chapter_info in chapter_info_list:</span><br><span class="line">    chapter_url,chapter_title = chapter_info</span><br><span class="line">    chapter_url = &quot;http://www.xbiqugew.com&quot; + chapter_url</span><br><span class="line">    </span><br><span class="line">    chapter_response = requests.get(chapter_url)</span><br><span class="line">    chapter_response.encoding=&apos;gbk&apos;</span><br><span class="line">    chapter_html=chapter_response.text</span><br></pre></td></tr></table></figure>

<p>通过for循环下载每一章小说的内容，这里的代码也只是重复之前的过程：获取网页、抓取网页中需要的内容，这里再用一个循环循环每一章节，将每章小说抓取下来。</p>
<blockquote>
<p>清洗数据  </p>
</blockquote>
<p>这里抓取出来的小说还有很多杂乱的、我们不想要的数据在里面，比如：很多空格，html中的空格代码 &amp;nbsp 和换行标签 &lt; /br&gt;等等。可以使用replace置换。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">chapter_content = chapter_content.replace(&apos; &apos;,&apos;&apos;)</span><br><span class="line">chapter_content = chapter_content.replace(&apos;&amp;nbsp&apos;,&apos;&apos;)</span><br><span class="line">chapter_content = chapter_content.replace(&apos;&lt;br/&gt;&apos;,&apos;&apos;)</span><br><span class="line">``/</span><br><span class="line">这里我也出了一个问题：我在之前的chpter_content是list格式，但是list无法使用replace，最开始用join还是报错，最后直接使用str()转换成字符串。  </span><br><span class="line"></span><br><span class="line">&gt;数据持久化储存</span><br></pre></td></tr></table></figure>

<p>fp = open(‘%s.txt’%title,’w’,encoding=’utf-8’<br>fp.write(chapter_title)<br>fp.write(chapter_content)<br>fp.write(‘\n’)<br>```<br>将抓取的小说存储到txt文档中</p>
<p>最后给大家看看我抓的小说  </p>
<p><img src="https://i.loli.net/2020/01/15/F3pDyA98XoV1tne.jpg" alt="乱七八槽的小说"><br>当然我这个也还需要改进。源码今天看已经找不到了，后面再补上。</p>

      
    </div>
    
    <footer>
        <div class="alignright">
          
          <a href='javascript:void(0)' class="share-link bdsharebuttonbox" data-cmd="more">分享</a>
        </div>
        
        
  
  <div class="tags">
    <a href="/tags/python/">-python</a>
  </div>

        <!-- partial('post/share') -->
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Search">
    <input type="hidden" name="q" value="site:yoursite.com">
  </form>
</div>

  

  
<div class="widget tag">
  <h3 class="title">Recent Posts</h3>
  <ul class="entry">
    
      <li>
        <a href="/2020/02/04/Java基础（二）：基本语法/">Java基础（二）：基本语法</a>
      </li>
    
      <li>
        <a href="/2020/01/31/Java基础（一）：了解Java/">Java基础（一）：了解Java</a>
      </li>
    
      <li>
        <a href="/2019/09/23/python编写简易爬虫/">python编写简易爬虫</a>
      </li>
    
  </ul>
</div>


  
<div class="widget tag">
  <h3 class="title">Tags</h3>
  <ul class="entry">
  
    <li><a href="/tags/python/">-python</a><small>1</small></li>
  
    <li><a href="/tags/Java/">Java</a><small>1</small></li>
  
  </ul>
</div>


  
<div class="widget tagcloud">
  <h3 class="title">Tag Cloud</h3>
  <div class="entry">
    <a href="/tags/python/" style="font-size: 10px;">-python</a> <a href="/tags/Java/" style="font-size: 10px;">Java</a>
  </div>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  <p>
  
  &copy; 2020 Xiaoyi Qing
  
  All rights reserved.</p>
  <p>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></p>
</div>
<div class="clearfix"></div>

<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"1","bdMiniList":false,"bdPic":"","bdStyle":"2","bdSize":"16"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script></footer>
  <script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


<div id='bg'></div>
</body>
</html>